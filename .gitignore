import requests
from bs4 import BeautifulSoup
import time

def analyze_website(url):
    try:
        start = time.time()
        response = requests.get(url)
        load_time = time.time() - start

        if response.status_code != 200:
            print(f"Failed to retrieve {url}: Status code {response.status_code}")
            return

        soup = BeautifulSoup(response.text, 'html.parser')

        title = soup.title.string if soup.title else 'No title found'
        num_links = len(soup.find_all('a'))
        num_images = len(soup.find_all('img'))
        word_count = len(soup.get_text().split())

        print(f"--- Analysis of {url} ---")
        print(f"Status Code: {response.status_code}")
        print(f"Title: {title}")
        print(f"Load Time: {load_time:.2f} seconds")
        print(f"Number of Links: {num_links}")
        print(f"Number of Images: {num_images}")
        print(f"Total Words on Page: {word_count}")

    except Exception as e:
        print(f"Error analyzing {url}: {e}")

# Example usage
if __name__ == "__main__":
    url = input("Enter a website URL (with https://): ")
    analyze_website(url)

